= TigerGraph DB Release Notes
:description: Release notes for TigerGraph {page-component-version}
//:page-aliases: change-log.adoc, release-notes.adoc
:fn-preview: footnote:preview[Features in the preview stage should not be used for production purposes. General Availability (GA) versions of the feature will be available in a later release.]
:pp: {plus}{plus}
:toc:
:toclevels:2

TigerGraph Server 4.1.0 preview version was released on August 28, 2024.

//LTS versions are supported for 24 months from their initial release (X.X.0) and should be the choice for production deployments.

== Key New Features

//text to comment out

== Detailed List of New and Modified Features

=== Backup and Restore Enhancements

* **Point in Time Restore** - Users can roll back the database to a moment they select, not only at the time of the available backup snapshots. https://graphsql.atlassian.net/browse/DOC-2187 to *review*

* **xref:tigergraph-server:backup-and-restore:configurations.adoc#_configure_backup_to_aws_s3_endpoint[Role ARN for Backup to AWS S3 buckets]** - Users can use AWS Role ARNs (Amazon Resource Names) for convenient and secure management of backups. 

* See also HA Enhancements.

=== Security Enhancements

[#finer_grain_query_privileges]
* **xref:tigergraph-server:user-access:fine-grained-query-privileges.adoc[Fine-grained Privileges on Queries]**
- Gives adminstrators finer control over who may do what actions with which objects
- Introduces ownership of graph and query objects.
- Allows privileges to be granted/revoked at the query level.
- Adds new query privileges INSTALL and EXECUTE, and splits  WRITE to CREATE, UPDATE and DROP.

* **xref:tigergraph-server:user-access:jwt-token.adoc#_usage_of_gsql_jwt_token[JWT Authentication]**
- https://graphsql.atlassian.net/browse/DOC-2129 to *Write*
- Users can generate and use JWT tokens when sending REST requests to the GSQL or REST servers.
- JWT authorization/authentication is more secure than the plaintext token used in earlier TigerGraph versions.
* **Password Complexity and Rotation Rules**
https://graphsql.atlassian.net/browse/DOC-2103 to *Write*
- Administrators can specify rules for the complexity of passwords and for how long or how many times a password may be used before it must be updated.
- Such rules improve security and help organziations to satisfy compliance requirements.

* **xref:tigergraph-server:troubleshooting:audit-log.adoc[Expanded Audit Log Coverage]**
- Audit logs now include `gadmin` activity, for more complete audit coverage.

=== High Availability (HA) Enhancements

* **Data Streaming HA**
- https://graphsql.atlassian.net/browse/DOC-2203 to *Write*
- In the event of a node failure, the connectors can detect the issue and failover to other active nodes, continuing the data loading process without requiring manual intervention.
-  Available for data streaming connectors, including data sources such Kafka and cloud storage on AWS, Azure, and Google Cloud.

* **xref:tigergraph-server:system-management:change-data-capture/cdc-overview.adoc#_cdc_ha[Change Data Capture (CDC) HA]**
- CDC continues to function as long as at least one replica per partition is online.
Previously, Replica 1 needed to remain operational.

* **Backup HA**
- Backups remain available even if a node fails.
Previously, backups were unavailable if a node failed.

=== Data Streaming/Connector Enhancements

* **Malformed Loading Data Inspector**
- *Don't see doc ticket*

The Malformed Loading Data Inspector allows users to inspect sampled error data from a loading job, along with the reasons for the errors.
Users can easily locate error data, which helps them modify their source data and loading job definitions. The error data is also protected by existing ACLs, ensuring it is secured and no longer exposed in files.

* **Spark Connector - Streaming Read**
- https://graphsql.atlassian.net/browse/DOC-2130 to *Write*. Ticket had generic title and no description.
- Using the Spark data source reader API, users can run TigerGraph queries, stream the output to Spark, and then read Spark DataFrames.
- Streaming the output lifts the 2GB query response size limitation for non-streaming output.
* **Notification for Stuck Loader**
- *Don't see doc ticket*
- If loading is stuck or acting abnormally, the loader sends an alert message to the console.
- The message includes a diagnosis of the cause, enabling users to take timely action instead of waiting indefinitely for the process to complete.


=== Kubernetes Operator Enhancements

* **Supporting Multi-AZ Cluster Resiliency for Better High Availability and Efficiency**

The Multi-AZ cluster resiliency feature allows users to enable region-aware replica placement of TigerGraph and configure topologySpreadConstraints for TigerGraph Pods.
This feature empowers users to achieve enhanced high availability and efficient resource utilization within TigerGraph deployments.

* **Supporting Expanding PVC Automatically**

The expanding PVC automatically feature allows users to increase the Persistent Volume size automatically by configuring the TigerGraph Custom Resource (CR).
Customers can expand the storage of clusters by modifying the storage size in the TigerGraph CR, with the TigerGraph Operator handling the automatic expansion of all PVCs, eliminating the need for manual intervention.

* **Supporting the Creation of Services for Sidecar Containers**

This feature allows users to configure services for sidecar containers during cluster deployment, with the TigerGraph Operator responsible for the service creation and updating.
Users no longer need to manage the details of Kubernetes service creation for TigerGraph pods to expose sidecar container services, as the process is automated for easier use, similar to other configurations in the TigerGraph CR.

=== Language Enhancements

* **GSQL OpenCypher additions**
- *It is annoying to me as a writer and to readers that these are listed as separate bullet points without a logical reason for the separation. It is actually 5 separate doc tickets. Working incrementally without a top-down view leads to poor results.*
- https://graphsql.atlassian.net/browse/DOC-2249 to *WRITE*

- Adds elementId() function to GSQL and GSQL OpenCypher.
- Adds head, last, size, tail, and reversedlist functions to GSQL and GSQL OpenCypher.
- Adds StartNode and EndNode functions to GSQL for use in GSQL OpenCypher.
- Introduces Range() and Split() functions to GSQL and OpenCypher.
- Introduces stDevP() function for population standard deviation in GSQL and OpenCypher.

* **REST APIs for Programmatic Use**
- https://graphsql.atlassian.net/browse/DOC-2194 to *REVIEW*
- Adds several new REST endpoints, to provide complete coverage for defining schema, loading data, querying, updating data, and managing database-related tasks.
- Introduces a REST API format that follows standard practices, empowering users to interact with TigerGraph programmatically, automate tasks, integrate databases with various applications, and leverage cloud services effectively, ultimately enhancing their development and operational efficiency.

* **xref:gsql-ref:querying:accumulators.adoc#_edge_attached_accumulators[Edge Accumulators in Multi-hop Queries]**
- Edge accumulators can now be using in multi-hop pattern matching queries.
- Query writers can save and retreive intermediate results using edge-based containers, enhancing the capabilities of the GSQL language for comprehensive graph data analysis.

NOTE: Haven't compared the below items against the DOC tickets yet.

== TigerGraph Suite

=== GraphStudio

* **Default User-Managed Layout**

Custom layout is now the default view in GraphStudio, allowing for a more personalized and efficient graph visualization experience. Users can hold the Option/Alt key while adjusting the layout if they still want the force layout effect..
This enhances user productivity by providing a tailored visual representation of their data while still allowing flexibility with the force layout effect when needed.
Also available in Insights.

* **Highlight Edges When Hovering Over a Vertex**

When a user hovers over a vertex in GraphStudio, the connected edges are now highlighted, making it easier to see relationships and connections at a glance. This visual aid helps in quickly identifying the structure and connections within the graph.
Users can more easily understand and analyze the relationships in their graph data, improving the efficiency of their data exploration.
Also available in Insights.

* **Collapsible Sidebar**

The sidebar in GraphStudio can now be collapsed, providing more screen space for graph visualization and manipulation. This feature allows users to maximize their workspace and focus on the graph itself.
By offering a cleaner and more spacious working environment, users can better concentrate on their graph data, enhancing overall usability and user experience.

* **Implement query_status Endpoint in GUI**

A new query_status endpoint has been added to the GUI for tracking the status of asynchronous query calls. This allows users to monitor the progress and completion of their queries without blocking their workflow.
Users can now manage and track their async queries more effectively, improving the efficiency of their workflow and resource management.

* **Mandatory Password Change upon Expiration**

GraphStudio now enforces users to change their password when it expires or when the password rotation period is due, enhancing security protocols. This feature ensures that users maintain strong and up-to-date passwords.
By enforcing regular password updates, users benefit from improved security, reducing the risk of unauthorized access to their graph data.
Not available on TigerGraph Cloud

* **Customizable Naming of Reverse Edges**

Users can now customize the naming of reverse edges in GraphStudio, providing greater flexibility in how relationships are represented and understood within the graph.
Customizable reverse edge naming helps users create more comprehensible and domain-specific graph models.

=== TigerGraph Insights

* **Downloadable Query Output**

Adds the capability to download query output as a CSV/JSON file in the table widget. This feature allows users to export the results of their queries directly into a CSV/JSON format for further analysis or reporting.
Users can easily export query results for further analysis, sharing, or reporting in other applications.

* **"Tree" View Respects Direction of Directed Edges**

The "Tree" view now respects the direction of directed edges. This enhancement ensures that hierarchical structures and dependencies are accurately represented according to the directionality of the edges.
Users gain a more accurate visualization of hierarchical data, improving their understanding of relationships and dependencies.

* **Support for Variables in Markdown Widget**

The Markdown widget now supports the use of variables. This feature allows users to dynamically insert variable values into their Markdown content, enabling more interactive and context-sensitive displays.
Users can create more dynamic and context-sensitive dashboards by incorporating variable data into their Markdown content.

=== AdminPortal

* **Health Check Tool**

- *Don't see a DOC ticket or existing documentation*

The Health Check Tool in TigerGraph AdminPortal provides administrators with a comprehensive utility to monitor and assess the health and performance of their TigerGraph system. This tool conducts various checks and diagnostics to ensure the system is running optimally.
Administrators can proactively identify and address potential issues, ensuring system reliability and optimal performance.

* **Fine-grained Query Privileges in RBAC**
AdminPortal UI for the xref:#finer_grain_query_privileges[fine-grained query privileges] described above.

== Fixed issues
=== Fixed and Improved in 4.1.0

//==== Functionality

////
* Fixed known issue where the attribute name `memberOf` was case-sensitive. It is now case-insensitive (GLE-6660).
* Fixed issue of clarity for error message/log when global `schema_change` failed for adding edge but it's relied on vertex does not exist (GLE-6751).
* Fixed issue where installation was halted due to TigerGraph disks mounted with `noexec` on AppRoot or DataRoot, preventing execution (TP-4929).
* Fixed issue where there was a delay in loading response times due to syntax detection process in GSQL (GLE-6822).
* Fixed issue were there was a GPE failure reported during query execution prompting relocation from `/tmp` to `System.TempRoot` (GLE-5536).
* Fixed issue where incorrect error response occurred when specified graph does not exist (APS-2824).
* Fixed issue where users encountered error `Vertex expansion failed: c.default.post is not a function` during Explore Neighbors operation in Insight (APS-2840).
////

//==== Crashes and Deadlocks
//==== Improvements
//==== Security
//==== Performance

== Known Issues and Limitations

[cols="4", separator=¦ ]
|===
¦ Description ¦ Found In ¦ Workaround ¦ Fixed In

¦When using xref:tigergraph-server:backup-and-restore:database-import-export.adoc[Import All] if a users schema size in the `.zip` file is exceedingly large, the import may fail with an error messages like this:

`Large catalog file key: /1/ReplicaList.json`

¦ 3.2
a¦
* 3.9 and below users need to run the import process manually by executing the GSQL scripts in the `.zip`.
* 3.10.0 and above users should xref:tigergraph-server:backup-and-restore:single-graph-import-export.adoc[import single or smaller batches of multiple graphs].
¦ TBD

a¦ If importing a role, policy, or function that has a different signature or content from the existing one, the one being imported will be skipped and not aborted.

.For example:
* If the original function is: `create function lib1.func2(int param1, float param2, string param3) returns (bool) {}`.
* And the user imports the new function: `create function lib1.func2(int param1) returns (bool) {}`. This second one will be skipped.
¦ 3.10.0
¦ Users need to re-create (delete and create) the imported role, policy, or function manually, and make sure that the importing one meets the requirements set by the existing one.
¦ TBD

a¦ xref:tigergraph-server:user-access:rbac-row-policy/row-policy-overview.adoc[Row Policy (Preview Feature)] does not yet filter or check vertex attribute data in upsert operations.

Such as,

* A query with insert statements.
* A file or Kafka loading job.
* A DDL loading request.
* Or a standard upsert request.
¦ 3.10.0
¦ Users should restrict the access of creating/running queries and loading jobs for roles related to row policy.
¦ TBD

¦ In file INPUT and OUTPUT policy, if there exists 2 path (`path1` and `path2`) in the configured policy list and `path1` is parent path of `path2`, then `path1` may not be effective.
¦ 3.2 and 3.10.0
¦ Users should avoid using paths if they are nested.

For example, avoid this scenario, path2 = `"/tmp/more"` and path1= `"/tmp"`.
¦ 3.10.1

¦ It has been observed that an issue happens when RESTPP will send a request to all gpes, and if one is down, the request sent to it will `timeout`.
Including the `consistency_check` request will also mark as `timeout`.
¦ 3.10.0
a¦
. Run `/rebuildnow` to rebuild all the segments.
+
[NOTE]
====
Running `/rebuildnow` when one gpe is down will result in the request timeout. This does not mean the request failed, instead only the currently running GPE will do the rebuild, and any rebuild requests sent to the down GPEs will result in a timeout.
====
. Run `/data_consistency_check?realtime=false` to check the consistency.
¦ TBD

¦ While running `export graph` if the disk space is not enough, or the data has not been detected, the export data will get stuck loading.
¦ 3.10.0
¦ Restart all services in Admin Portal or the backend.
¦ TBD

¦ `[tg_]ExprFunction.hpp` will be automatically merged while importing single graphs. In some cases, query compilation may fail.
¦ 3.10.0
¦ See xref:tigergraph-server:backup-and-restore:single-graph-import-export.adoc#_known_issues_and_workarounds[Known Issues and Workarounds]
¦ TBD

¦ Upgrading from a previous version of TigerGraph has known issues.
¦ 3.10.0
¦ See section xref:tigergraph-server:installation:upgrade.adoc#_known_issues_and_workarounds[Known Issues and Workarounds] for more details.
¦ TBD

¦ Input Policy feature has known limitations.
¦ 3.10.0
¦ See section xref:tigergraph-server:security:gsql-file-input-policy.adoc#_limitations[Input Policy Limitations] for more details.
¦ TBD

¦ Change Data Capture (CDC) feature has known limitations.
¦ 3.10.0
¦ See section xref:tigergraph-server:system-management:change-data-capture/cdc-overview.adoc#_cdc_limitations[CDC Limitations] for more details.
¦ TBD

¦ If the `FROM` clause pattern is a multi-hop and the `ACCUM` clause reads both primitive and container type attributes or accumulators of a vertex, the internal query rewriting logic may generate an invalid rewritten output.
¦ 3.9.3
¦ This results in the error message: `It is not allowed to mix primitive types and accumulator types in GroupByAccum`.
¦ TBD

¦ Users may see a high CPU usage caused by Kafka prefetching when there is no query or posting request.
¦ 3.9.3
¦ TBD
¦ TBD

¦ GSQL query compiler may report a false error for a valid query using a vertex set variable (e.g. `Ent` in `reverse_traversal_syntax_err`) to specify the midpoint or target vertex of a path in a FROM clause pattern.
¦ TBD
¦ TBD
¦ TBD

¦ If a loading job is expected to load from a large batch of files or Kafka queues (e.g. more than 500), the job’s status may not be updated for an extended period of time.
¦ 3.9.3
¦ In this case, users should check the loader log file as an additional reference for loading status.
¦ TBD

¦ When a GPE/GSE is turned off right after initiating a loading job, the loading job is terminated internally. However, users may still observe the loading job as running on their end.
¦ 3.9.3
¦ Please see xref:gsql-ref:ddl-and-loading:running-a-loading-job.adoc[Troubleshooting Loading Job Delays] for additional details.
¦ TBD

¦ For v3.9.1 and v3.9.2 when inserting a new edge in `GPR` and `INTERPRET` mode, the GPE will print out a warning message because a discriminator string is not set for new-inserted edges. Creating an inconsistent problem in delta message for GPR and `INTERPRET` mode.
¦ 3.9.2
¦ Please see xref:gsql-ref:ddl-and-loading:running-a-loading-job.adoc[Troubleshooting Loading Job Delays] for additional details.
¦ 3.9.3

¦ GSQL `EXPORT GRAPH` may fail and cause a GPE to crash when UDT type has a fixed STRING size.
¦ TBD
¦ TBD
¦ TBD

¦ After a global loading job is running for a while a fail can be encountered when getting the loading status due to `KAFKASTRM-LL` not being online, when actually the status is online.
Then the global loading process will exit and fail the local job after timeout while waiting the global loading job to finish.
¦ TBD
¦ TBD
¦ TBD

¦ When the memory usage approaches 100%, the system may stall because the process to elect a new GSE leader did not complete correctly.
¦ TBD
¦ This lockup can be cleared by restarting the GSE.
¦ TBD

¦ If the CPU and memory utilization remain high for an extended period during a schema change on a cluster, a GSE follower could crash, if it is requested to insert data belonging to the new schema before it has finished handling the schema update.
¦ TBD
¦ TBD
¦ TBD

¦ When available memory becomes very low in a cluster and there are a large number of vertex deletions to process, some remote servers might have difficulty receiving the metadata needed to be aware of all the deletions across the full cluster. The mismatched metadata will cause the GPE to go down.
¦ TBD
¦ TBD
¦ TBD

¦ Subqueries with SET<VERTEX> parameters cannot be run in Distributed or Interpreted mode.
¦ TBD
¦ (xref:3.9@gsql-ref:querying:operators-and-expressions.adoc#_subquery_limitations[Limited Distributed model support] is added in 3.9.2.)
¦ TBD

¦ Upgrading a cluster with 10 or more nodes to v3.9.0 requires a patch.
¦ 3.9
¦ Please contact TigerGraph Support if you have a cluster this large. Clusters with nine or fewer nodes do not require the patch.
¦ 3.9.1

¦ Downsizing a cluster to have fewer nodes requires a patch.
¦ 3.9.0
¦ Please contact TigerGraph Support.
¦ TBD

¦ During peak system load, loading jobs may sometimes display an inaccurate loading status.
¦ 3.9.0
¦ This issue can be remediated by continuing to run `SHOW LOADING STATUS` periodically to display the up-to-date status.
¦ TBD

¦ When managing many loading jobs, pausing a data loading job may result in longer-than-usual response time.
¦ TBD
¦ TBD
¦ TBD

¦ Schema change jobs may fail if the server is experiencing a heavy workload.
¦ TBD
¦ To remedy this, avoid applying schema changes during peak load times.
¦ TBD

¦ User-defined Types (UDT) do not work if exceeding string size limit.
¦ TBD
¦ Avoid using UDT for variable length strings that cannot be limited by size.
¦ TBD

¦ Unable to handle the tab character `\t` properly in AVRO or Parquet file loading. It will be loaded as `\\t`.
¦ TBD
¦ TBD
¦ TBD

¦ If `System.Backup.Local.Enable` is set to `true`, this also enables a daily full backup at 12:00am UTC.
¦ 3.9.0
¦ TBD
¦ 3.9.1

¦ The data streaming connector does not handle NULL values; the connector may operate properly if a NULL value is submitted.
¦ TBD
¦ Users should replace NULL with an alternate value, such as empty string "" for STRING data, 0 for INT data, etc.  (NULL is not a valid value for the TigerGraph graph data store.)
¦ TBD

¦ Automatic message removal is an Alpha feature of the Kafka connector. It has several xref:3.9@tigergraph-server:data-loading:load-from-cloud.adoc#_known_issues_with_loading[known issues].
¦ TBD
¦ TBD
¦ TBD

¦ The `DATETIME` data type is not supported by the `PRINT … TO CSV` statement.
¦ 3.9.0
¦ TBD
¦ 3.9.1

¦ The LDAP keyword `memberOf` for declaring group hierarchy is case-sensitive.
¦ 3.9
¦ Check the case of the keywords for `memberOf`. This has been fixed in versions 3.10.1 and above.
¦ 3.10.1

|===

=== Compatibility Issues

[cols="2", separator=¦ ]
|===
¦ Description ¦ Version Introduced

¦ Users could encounter file input/output policy violations when upgrading a TigerGraph version.
See xref:tigergraph-server:security:gsql-file-input-policy.adoc#_backward_compatibility[Input policy backward compatibility.]
¦ v3.10.0

¦ When a PRINT argument is an expression, the output uses the expression as the key (label) for that output value.
To better support Antlr processing, PRINT now removes any spaces from that key. For example, `count(DISTINCT @@ids)` becomes `count(DISTINCT@@ids)`.
¦ v3.9.3+

¦ Betweenness Centrality algorithm: `reverse_edge_type (STRING)` parameter changed to `reverse_edge_type_set (SET<STRING>)`, to be consistent with `edge_type_set` and similar algorithms.
¦ v3.9.2+

¦ For vertices with string-type primary IDs, vertices whose ID is an empty string will now be rejected.
¦ v3.9.2+

¦ The default mode for the Kafka Connector changed from EOF="false" to EOF="true".
¦ v3.9.2+

¦ The default retention time for two monitoring services `Informant.RetentionPeriodDays` and `TS3.RetentionPeriodDays` has reduced from 30 to 7 days.
¦ v3.9.2+

¦ The filter for `/informant/metrics/get/cpu-memory` now accepts a list of ServiceDescriptors instead of a single ServiceDescriptor.
¦ v3.9.2+

a¦ Some user-defined functions (UDFs) may no longer be accepted due to xref:security:index.adoc#_udf_file_scanning[increased security screening].

* UDFs may no longer be called `to_string()`. This is now a built-in GSQL function.
* UDF names may no longer use the `tg_` prefix. Any user-defined function that began with `tg_` must be renamed or removed in `ExprFunctions.hpp`.
¦ v3.9+
|===

=== Deprecations

[cols="3", separator=¦ ]
|===
¦ Description ¦ Deprecated ¦ Removed

¦ The use of plaintext tokens in xref:tigergraph-server:API:authentication.adoc[authentication] is deprecated.
Use xref:tigergraph-server:user-access:jwt-token.adoc[] instead.
¦ 3.10.0
¦ TBD


¦ The command `gbar` is removed and is no longer available.
However, if you are using a version of TigerGraph before 3.10.0 you can still use `gbar` to xref:tigergraph-server:backup-and-restore:gbar-legacy.adoc[create a backup with gbar] of the primary cluster.
See also xref:tigergraph-server:backup-and-restore:gbar-legacy.adoc[Backup and Restore with gbar] on how to create a backup.

¦ 3.7
¦ 3.10.0

¦ xref:tigergraph-server:user-access:vlac.adoc[Vertex-level Access Control (VLAC)] and xref:gsql-ref:querying:func/vertex-methods.adoc#_vlac_vertex_alias_methods_deprecated[VLAC Methods] are now deprecated and will no longer be supported.
¦ 3.10.0
¦ 4.0

¦ xref:tigergraph-server:data-loading:spark-connection-via-jdbc-driver.adoc[Spark Connection via JDBC Driver] is now deprecated and will no longer be supported.
¦ 3.10.0 
¦ TBD

¦ `Build Graph Patterns` is deprecated and will not be updated or supported and instead
we are focusing on xref:insights:widgets:index.adoc[Insights] as the tool of choice for building visual queries.
¦ v3.9.3
¦ TBD

¦ Kubernetes classic  mode (non-operator) is deprecated.
¦ v3.9
¦ TBD

¦ The `WRITE_DATA` RBAC privilege is deprecated.
¦ v3.7
¦ TBD
|===

== Release notes for previous versions
* xref:3.10@tigergraph-server:release-notes:index.adoc[Release notes - TigerGraph 3.10]
* xref:3.9@tigergraph-server:release-notes:index.adoc[Release notes - TigerGraph 3.9]
* xref:3.8@tigergraph-server:release-notes:index.adoc[Release notes - TigerGraph 3.8]
* xref:3.7@tigergraph-server:release-notes:index.adoc[Release notes - TigerGraph 3.7]
* xref:3.6@tigergraph-server:release-notes:index.adoc[Release notes - TigerGraph 3.6]
* xref:3.5@tigergraph-server:release-notes:index.adoc[Release notes - TigerGraph 3.5]
* xref:3.4@tigergraph-server:release-notes:release-notes.adoc[Release notes - TigerGraph 3.4]
* xref:3.3@tigergraph-server:release-notes:release-notes.adoc[Release notes - TigerGraph 3.3]
* xref:3.2@tigergraph-server:release-notes:release-notes.adoc[Release notes - TigerGraph 3.2]
